from pathlib import Path
from typing import List
import cv2
import numpy as np
from ultralytics import YOLO
from ml.action_classifier import classify_action_from_clip, extract_clip
from utils.logger import logger


def analyze_video_pipeline(
    video_path: str, max_frames: int = 300, stride: int = 5
) -> List[str]:
    """
    ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ°ÑÐºÐ°Ð´Ð° YOLO + action classifier.
    ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ `max_frames` ÐºÐ°Ð´Ñ€Ð¾Ð² Ñ ÑˆÐ°Ð³Ð¾Ð¼ `stride`.
    """
    logger.info(f"ðŸš€ ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ð¸Ð´ÐµÐ¾: {video_path}")
    cap = cv2.VideoCapture(video_path)
    yolo_model = YOLO("yolov8n.pt")

    frame_idx = 0
    actions = []

    frames = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret or frame_idx > max_frames:
            break

        if frame_idx % stride == 0:
            results = yolo_model(frame)[0]
            for box in results.boxes.data.tolist():
                x1, y1, x2, y2, score, cls = box
                if int(cls) == 0:  # Ñ‚Ð¾Ð»ÑŒÐºÐ¾ 'person'
                    person = frame[int(y1) : int(y2), int(x1) : int(x2)]
                    if person.size == 0:
                        continue
                    person_rgb = cv2.cvtColor(person, cv2.COLOR_BGR2RGB)
                    frames.append(person_rgb)

        frame_idx += 1

    cap.release()

    if len(frames) < 16:
        logger.warning(f"âš ï¸ Ð¡Ð»Ð¸ÑˆÐºÐ¾Ð¼ Ð¼Ð°Ð»Ð¾ ÐºÐ°Ð´Ñ€Ð¾Ð² Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ: {len(frames)}")
        return []

    # ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð¿Ð¾ ÑÐ¾Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¼ ÐºÐ°Ð´Ñ€Ð°Ð¼
    try:
        label = classify_action_from_clip(frames)
        actions.append(label)
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸: {e}")

    logger.info(f"âœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾: Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(actions)} Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹")
    return actions
